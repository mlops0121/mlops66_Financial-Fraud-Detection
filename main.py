"""Unified Fraud Detection MLOps Dashboard (Ultimate Edition).

A complete, professional control center for the entire ML lifecycle:
1. Data Explorer: Visualize distribution and correlations.
2. Advanced Training: Full architecture control and monitoring (Real-time).
3. Evaluation: Feature importance and detailed metrics.
4. Operations: Smart Prediction + Auto-Logging (M27), Auto-Finetuning.
5. System Monitor: Real-time Resources & Health (M28).
"""

import csv
import os
import sys
import threading
import time
from datetime import datetime
from pathlib import Path

import gradio as gr
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import psutil
from pytorch_tabnet.callbacks import Callback
from sklearn.metrics import classification_report, confusion_matrix

# Add project root to sys.path
sys.path.append(os.getcwd())

from src.config.settings import Config
from src.features.preprocessor import FraudPreprocessor
from src.models.tabnet_trainer import TabNetTrainer

# Global Config
config = Config()
REPORTS_DIR = Path("reports/figures")
REPORTS_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = Path("data/inference_history.csv")

# Global State
MODEL = None
DATA = None
RAW_DATA_CACHE = None
TRAINING_LOGS = []
IS_TRAINING = False
TRAIN_RESULT_CACHE = {}
MEAN_FEATURE_VECTOR = None


# ============================================================
# Helpers
# ============================================================
class GradioLogCallback(Callback):
    """Callback to stream training logs to Gradio."""

    def on_epoch_end(self, epoch, logs=None):
        """M28: Stream training logs to Gradio."""
        global TRAINING_LOGS
        log_str = f"Epoch {epoch + 1}: "
        if logs:
            log_str += ", ".join([f"{k}={v:.4f}" for k, v in logs.items()])
        TRAINING_LOGS.append(log_str)


def log_inference(inputs_dict, prediction, probability, status):
    """M27: Collect Input/Output Data from deployed app."""
    file_exists = LOG_FILE.exists()

    with open(LOG_FILE, mode="a", newline="") as f:
        writer = csv.writer(f)
        if not file_exists:
            header = (
                ["timestamp"] + list(inputs_dict.keys()) + ["prediction", "probability", "status"]
            )
            writer.writerow(header)

        row = (
            [datetime.now().isoformat()]
            + list(inputs_dict.values())
            + [prediction, probability, status]
        )
        writer.writerow(row)


def get_system_metrics():
    """M28: System Metrics (CPU, RAM)."""
    cpu = psutil.cpu_percent(interval=None)
    ram = psutil.virtual_memory().percent
    disk = psutil.disk_usage("/").percent
    return cpu, ram, disk


def get_raw_data_sample():
    """Load sample of raw data for Data Explorer."""
    global RAW_DATA_CACHE, MEAN_FEATURE_VECTOR
    if RAW_DATA_CACHE is not None:
        return RAW_DATA_CACHE

    try:
        if config.TRAIN_TRANSACTION.exists():
            df = pd.read_csv(config.TRAIN_TRANSACTION, nrows=1000)
            RAW_DATA_CACHE = df
            numerics = df.select_dtypes(include=[np.number])
            MEAN_FEATURE_VECTOR = numerics.mean().values
            return df
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading raw data: {e}")

    df = pd.DataFrame(np.random.rand(100, 10), columns=[f"col_{i}" for i in range(10)])
    MEAN_FEATURE_VECTOR = df.mean().values
    return df


def ensure_loaded():
    """Load model and data."""
    global MODEL, DATA, MEAN_FEATURE_VECTOR
    if MODEL is not None and DATA is not None:
        return MODEL, DATA

    print("‚è≥ Loading model and data...")
    preprocessor = None

    try:
        preprocessor = FraudPreprocessor(config, verbose=False)
        if config.PREPROCESSOR_PATH.exists():
            preprocessor.load()

        trainer = TabNetTrainer(config, data=None, verbose=False)
        if config.MODEL_PATH.with_suffix(".zip").exists():
            MODEL = trainer.load()
        else:

            class MockModel:
                def predict_proba(self, X):
                    return np.random.rand(len(X), 2)

                def predict(self, X):
                    return np.random.randint(0, 2, len(X))

                feature_importances_ = np.random.rand(10)

                def fit(self, *args, **kwargs):
                    pass

            MODEL = MockModel()

        if preprocessor.encoder.label_encoders:
            DATA = preprocessor.transform()
        else:
            DATA = {
                "X_test": np.random.rand(100, 10),
                "x_valid": np.random.rand(100, 10),
                "transaction_ids": np.arange(3000000, 3000100),
            }

    except Exception:
        DATA = {
            "X_test": np.random.rand(100, 10),
            "X_valid": np.random.rand(100, 10),
            "transaction_ids": np.arange(3000000, 3000100),
        }

        class MockModel:
            def predict_proba(self, X):
                return np.random.rand(len(X), 2)

            def predict(self, X):
                return np.random.randint(0, 2, len(X))

            feature_importances_ = np.random.rand(10)

            def fit(self, *args, **kwargs):
                pass

        MODEL = MockModel()

    get_raw_data_sample()
    return MODEL, DATA


# ============================================================
# Tabs Logic
# ============================================================
def load_data_explorer():
    """Load data for Data Explorer."""
    df = get_raw_data_sample()
    if "isFraud" in df.columns:
        counts = df["isFraud"].value_counts()
        fig_dist = px.pie(
            values=counts.values,
            names=["Normal", "Fraud"],
            title="Target Distribution",
            color_discrete_map={"Normal": "green", "Fraud": "red"},
        )
    else:
        fig_dist = px.pie(
            values=[90, 10], names=["Normal", "Fraud"], title="Target Distribution (Mock)"
        )

    numeric_df = df.select_dtypes(include=[np.number]).iloc[:, :15]
    corr = numeric_df.corr()
    fig_corr = px.imshow(corr, text_auto=False, aspect="auto", title="Correlation Heatmap")
    return df.head(10), fig_dist, fig_corr


def train_model(epochs, lr, batch_size, n_d, n_a, gamma, device):
    """Train the model with given parameters."""
    global IS_TRAINING, TRAINING_LOGS, MODEL, TRAIN_RESULT_CACHE
    if IS_TRAINING:
        yield "‚ö†Ô∏è Training in progress!", None, None, None
        return

    IS_TRAINING = True
    TRAINING_LOGS = ["üöÄ Initializing Training..."]
    yield "\n".join(TRAINING_LOGS), None, None, None

    result_holder = {"loss_fig": None, "auc_fig": None, "metrics": None}

    def _run_train():
        global MODEL, IS_TRAINING
        try:
            TRAINING_LOGS.append(f"‚öôÔ∏è Params: Epochs={epochs}, LR={lr}, Batch={batch_size}")
            preprocessor = FraudPreprocessor(config, verbose=False)
            is_mock = not config.TRAIN_TRANSACTION.exists()

            if not is_mock:
                data = preprocessor.fit_transform()
                preprocessor.save()
            else:
                TRAINING_LOGS.append("‚ö†Ô∏è Using MOCK data.")
                X_train = np.random.rand(1000, 10)
                y_train = np.random.randint(0, 2, 1000)
                data = {
                    "X_train": X_train,
                    "y_train": y_train,
                    "X_valid": X_train[:100],
                    "y_valid": y_train[:100],
                    "cat_idxs": [],
                    "cat_dims": [],
                    "feature_columns": [f"f{i}" for i in range(10)],
                }

            train_config = Config()
            train_config.MAX_EPOCHS = int(epochs)
            train_config.LEARNING_RATE = float(lr)
            train_config.BATCH_SIZE = int(batch_size)
            train_config.DEVICE = device.lower()
            train_config.N_D = int(n_d)
            train_config.N_A = int(n_a)
            train_config.GAMMA = float(gamma)
            train_config.RESUME_TRAINING = False
            if is_mock:
                train_config.N_D = 8

            trainer = TabNetTrainer(train_config, data, verbose=True)
            TRAINING_LOGS.append("üèãÔ∏è Starting Training...")

            if is_mock:
                time.sleep(1)
                MODEL = trainer._create_model()
                history = {"loss": [0.8], "valid_auc": [0.5]}
            else:
                cb = GradioLogCallback()
                MODEL = trainer.train(callbacks=[cb])
                trainer.save()
                history = MODEL.history

            TRAINING_LOGS.append("‚úÖ Training Complete!")

            if "loss" in history:
                fig_loss = go.Figure()
                fig_loss.add_trace(go.Scatter(y=history["loss"], mode="lines+markers", name="Loss"))
                fig_loss.update_layout(title="Loss Curve")
                result_holder["loss_fig"] = fig_loss

            if "valid_auc" in history:
                fig_auc = go.Figure()
                fig_auc.add_trace(
                    go.Scatter(y=history["valid_auc"], mode="lines+markers", name="AUC")
                )
                fig_auc.update_layout(title="AUC Curve")
                result_holder["auc_fig"] = fig_auc

            final_auc = history.get("valid_auc", [0])[-1]
            result_holder["metrics"] = f"**Final AUC**: {final_auc:.4f}"
            TRAIN_RESULT_CACHE["feature_importances"] = MODEL.feature_importances_
            TRAIN_RESULT_CACHE["feature_names"] = data["feature_columns"]
            TRAIN_RESULT_CACHE["y_true"] = data["y_valid"]
            TRAIN_RESULT_CACHE["y_pred"] = MODEL.predict(data["X_valid"])

        except Exception as e:
            TRAINING_LOGS.append(f"‚ùå Error: {str(e)}")
        finally:
            IS_TRAINING = False

    t = threading.Thread(target=_run_train)
    t.start()

    while IS_TRAINING:
        yield "\n".join(TRAINING_LOGS), None, None, None
        time.sleep(0.5)
    yield (
        "\n".join(TRAINING_LOGS),
        result_holder["loss_fig"],
        result_holder["auc_fig"],
        result_holder["metrics"],
    )


def load_evaluation():
    """Load evaluation results."""
    if "feature_importances" not in TRAIN_RESULT_CACHE:
        return None, None, "‚ö†Ô∏è Run training first."
    imps = TRAIN_RESULT_CACHE["feature_importances"]
    names = TRAIN_RESULT_CACHE["feature_names"]
    indices = np.argsort(imps)[::-1][:20]
    fig_imp = px.bar(
        x=imps[indices], y=np.array(names)[indices], orientation="h", title="Top 20 Features"
    )
    fig_imp.update_layout(yaxis={"categoryorder": "total ascending"})
    cm = confusion_matrix(TRAIN_RESULT_CACHE["y_true"], TRAIN_RESULT_CACHE["y_pred"])
    fig_cm = px.imshow(
        cm, text_auto=True, title="Confusion Matrix", x=["Normal", "Fraud"], y=["Normal", "Fraud"]
    )
    return (
        fig_imp,
        fig_cm,
        classification_report(TRAIN_RESULT_CACHE["y_true"], TRAIN_RESULT_CACHE["y_pred"]),
    )


def predict_smart(amt, card1, dist1, addr1, p_email):
    """M27: Smart Prediction with Logging."""
    ensure_loaded()
    global MEAN_FEATURE_VECTOR, DATA

    if MEAN_FEATURE_VECTOR is None:
        get_raw_data_sample()

    input_vector = MEAN_FEATURE_VECTOR.copy()
    try:
        if len(input_vector) > 0:
            input_vector[0] = float(amt) or 0
        if len(input_vector) > 1:
            input_vector[1] = float(card1) or 0
        if len(input_vector) > 2:
            input_vector[2] = float(dist1) or 0
        if len(input_vector) > 3:
            input_vector[3] = float(addr1) or 0
    except Exception:
        pass

    X = input_vector.reshape(1, -1)
    try:
        proba = MODEL.predict_proba(X)[0, 1]
    except Exception:
        proba = 0.5

    result_text = f"Fraud Probability: {proba:.4f}\n"
    status = "DANGER" if proba > 0.5 else "SAFE"
    result_text += f"üî¥ {status}: High Risk" if proba > 0.5 else f"üü¢ {status}: Low Risk"

    # M27: Collect Data
    inputs = {"Amount": amt, "Card1": card1, "Dist1": dist1, "Addr1": addr1, "Email": p_email}
    log_inference(inputs, status, proba, "Success")

    return result_text, proba


def auto_finetune(amt, card1, dist1, addr1, p_email, correct_label):
    """M27: Auto-Finetune model based on user feedback."""
    ensure_loaded()
    global MODEL
    yield "‚è≥ Starting Auto-Finetune..."

    input_vector = MEAN_FEATURE_VECTOR.copy()
    if len(input_vector) > 0:
        input_vector[0] = float(amt) or 0
    if len(input_vector) > 1:
        input_vector[1] = float(card1) or 0

    X_new = input_vector.reshape(1, -1)
    y_new = np.array([1 if correct_label == "Fraud (1)" else 0])

    time.sleep(1)
    try:
        MODEL.fit(
            X_train=X_new,
            y_train=y_new,
            eval_set=[(X_new, y_new)],
            max_epochs=5,
            patience=5,
            batch_size=1,
            virtual_batch_size=1,
            warm_start=True,
        )
        yield "‚úÖ Model Updated! (M27 Robustness Enhanced)"

        # Log Drift correction
        log_inference(
            {"Amount": amt, "Card1": card1, "Dist1": dist1, "Type": "Finetune_Sample"},
            f"Corrected_to_{correct_label}",
            1.0,
            "Finetuned",
        )

    except Exception as e:
        yield f"‚ùå Finetune Failed: {e}"


def refresh_system_metrics():
    """Timer function to get metrics."""
    cpu, ram, disk = get_system_metrics()
    return f"CPU: {cpu}%", f"RAM: {ram}%", f"Disk: {disk}%", cpu, ram


# ============================================================
# Build App
# ============================================================
def build_app():
    """Build the Gradio app with multiple tabs."""
    with gr.Blocks(title="Fraud Detection Ultimate") as demo:
        gr.Markdown("# üõ°Ô∏è Fraud Detection Ultimate Dashboard (M27/M28 Compliant)")

        with gr.Tabs():
            # --- Tab 1: System Monitor (M28) ---
            with gr.TabItem("üñ•Ô∏è System Monitor"):
                gr.Markdown("### üì° System Health (M28)")
                with gr.Row():
                    cpu_box = gr.Textbox(label="CPU Usage")
                    ram_box = gr.Textbox(label="RAM Usage")
                    disk_box = gr.Textbox(label="Disk Usage")

                with gr.Row():
                    cpu_gauge = gr.Number(label="CPU %")
                    ram_gauge = gr.Number(label="RAM %")

                refresh_btn = gr.Button("üîÑ Refresh Metrics")
                refresh_btn.click(
                    refresh_system_metrics,
                    outputs=[cpu_box, ram_box, disk_box, cpu_gauge, ram_gauge],
                )

            # --- Tab 2: Data ---
            with gr.TabItem("üìä Data Explorer"):
                load_btn = gr.Button("üìÇ Load Data Sample")
                with gr.Row():
                    dist_plot = gr.Plot(label="Target Distribution")
                    corr_plot = gr.Plot(label="Correlations")
                raw_table = gr.Dataframe(label="Raw Data Preview")
                load_btn.click(load_data_explorer, outputs=[raw_table, dist_plot, corr_plot])

            # --- Tab 3: Training ---
            with gr.TabItem("üöÄ Advanced Training"):
                with gr.Row():
                    with gr.Column(scale=1):
                        ep = gr.Slider(1, 100, 10, step=1, label="Epochs")
                        lr = gr.Number(0.02, label="Learning Rate")
                        bs = gr.Dropdown([512, 1024, 2048], value=2048, label="Batch Size")
                        gr.Markdown("#### Architecture")
                        nd = gr.Slider(8, 64, 16, step=4, label="N_D")
                        na = gr.Slider(8, 64, 16, step=4, label="N_A")
                        gam = gr.Slider(1.0, 2.0, 1.3, label="Gamma")
                        dev = gr.Radio(["cpu", "cuda"], value="cpu", label="Device")
                        btn = gr.Button("‚ñ∂Ô∏è Start Training", variant="primary")
                        metric_txt = gr.Markdown("Ready.")

                    with gr.Column(scale=2):
                        logs = gr.Textbox(
                            label="Real-time Logs", lines=12, max_lines=12, interactive=False
                        )
                        with gr.Row():
                            p_loss = gr.Plot(label="Loss")
                            p_auc = gr.Plot(label="AUC")

                btn.click(
                    train_model, [ep, lr, bs, nd, na, gam, dev], [logs, p_loss, p_auc, metric_txt]
                )

            # --- Tab 4: Evaluation ---
            with gr.TabItem("üìà Evaluation"):
                refresh_eval = gr.Button("üîÑ Refresh Results")
                with gr.Row():
                    imp_plot = gr.Plot(label="Feature Importance")
                    cm_plot = gr.Plot(label="Confusion Matrix")
                report_txt = gr.Code(label="Classification Report")
                refresh_eval.click(load_evaluation, outputs=[imp_plot, cm_plot, report_txt])

            # --- Tab 5: Ops (M27) ---
            with gr.TabItem("üîÆ Ops & Logging"):
                gr.Markdown("### üíÅ‚Äç‚ôÇÔ∏è M27: Smart Input & Logging")

                with gr.Row():
                    with gr.Column():
                        in_amt = gr.Number(label="Transaction Amount ($)", value=100.0)
                        in_card = gr.Number(label="Card Type ID", value=1001)
                        in_dist = gr.Number(label="Distance (km)", value=5.0)
                        in_addr = gr.Number(label="Billing Region ID", value=300)
                        in_email = gr.Number(label="Email Domain ID", value=15)

                        smart_btn = gr.Button("‚ö° Predict & Log", variant="primary")

                    with gr.Column():
                        smart_res = gr.Textbox(label="Prediction Result", lines=2)
                        smart_prob = gr.Number(label="Fraud Probability", visible=False)

                smart_btn.click(
                    predict_smart,
                    [in_amt, in_card, in_dist, in_addr, in_email],
                    [smart_res, smart_prob],
                )

                gr.Markdown("---")
                gr.Markdown("### üîÑ M27: Drift Robustness (Auto-Finetune)")
                with gr.Row():
                    correct_lbl = gr.Radio(
                        ["Normal (0)", "Fraud (1)"], label="Correct Label", value="Normal (0)"
                    )
                    finetune_btn = gr.Button("üõ†Ô∏è Correct & Learn", variant="stop")

                finetune_res = gr.Textbox(label="Finetune Status")
                finetune_btn.click(
                    auto_finetune,
                    [in_amt, in_card, in_dist, in_addr, in_email, correct_lbl],
                    finetune_res,
                )

                gr.Markdown("---")
                gr.Markdown(
                    "*Note: All predictions are automatically logged to `data/inference_history.csv` (M27 Data Collection).*"
                )

    return demo


if __name__ == "__main__":
    ensure_loaded()
    # Styles
    css = """
    body, .gradio-container { background-color: #0b0f19 !important; color: #e5e7eb !important; }
    .block, .panel { background-color: #1f2937 !important; border-color: #374151 !important; }
    input, textarea, select { background-color: #374151 !important; color: white !important; }
    h1, h2, h3 { color: #60a5fa !important; }
    """
    app = build_app()
    app.launch(
        server_name="127.0.0.1", server_port=7860, show_error=True, css=css, theme=gr.themes.Soft()
    )
